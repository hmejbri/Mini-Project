{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBtk_tC8zmC1"
   },
   "source": [
    "# Houssem Mejbri\n",
    "\n",
    "## PDF → Langchain → Flask → Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v8fCmC-6Q3pP"
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS, cross_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the OpenAI's API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_aQ7ps_dRJOq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read pdf file and return its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_FA1ZERdRLAM"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "\n",
    "def readFile(fileName):\n",
    "    # provide the path of  pdf file\n",
    "    pdfreader = PdfReader(fileName)\n",
    "    \n",
    "    # read text from pdf\n",
    "    raw_text = ''\n",
    "    for i, page in enumerate(pdfreader.pages):\n",
    "        content = page.extract_text()\n",
    "        if content:\n",
    "            raw_text += content\n",
    "            \n",
    "    #returns the raw text inside the pdf file        \n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VP6ap_PSRt7s"
   },
   "outputs": [],
   "source": [
    "# We need to split the text using Character Text Split such that it should not increase token size\n",
    "def splitText(raw_text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator = \"\\n\",\n",
    "        chunk_size = 800,\n",
    "        chunk_overlap  = 200,\n",
    "        length_function = len,\n",
    "    )\n",
    "    return text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wqy4vJhrSXUT"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "document_search = None\n",
    "\n",
    "def createChain(texts):\n",
    "    global document_search\n",
    "    # Download embeddings from OpenAI\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # Create a document search index\n",
    "    document_search = FAISS.from_texts(texts, embeddings)\n",
    "    # create a chain to answer questions\n",
    "    chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS, cross_origin\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "# Enable CORS with specific configurations\n",
    "CORS(app, supports_credentials=True, allow_headers=['Content-Type'], methods=['POST', 'OPTIONS'])\n",
    "\n",
    "# Initialize global variables\n",
    "chain = None  # Initialize chain as None initially\n",
    "document_search = None  # Initialize document_search as None initially\n",
    "\n",
    "# Upload file API endpoint\n",
    "@app.route(\"/upload\", methods=[\"POST\", \"OPTIONS\"])\n",
    "@cross_origin(origin='*')\n",
    "def uploadFile():\n",
    "    global chain  # Use the global keyword to modify the global variable\n",
    "    uploaded_file = request.files['file']\n",
    "    uploaded_file.save(\"./\" + uploaded_file.filename)\n",
    "    \n",
    "    # Read raw text from the uploaded file\n",
    "    raw_text = readFile(uploaded_file.filename)\n",
    "    \n",
    "    # Split raw text into individual texts\n",
    "    texts = splitText(raw_text)\n",
    "    \n",
    "    # Create a chain based on the extracted texts\n",
    "    chain = createChain(texts)\n",
    "    \n",
    "    # Respond with a JSON indicating success\n",
    "    return jsonify({\"message\": \"File uploaded successfully\"}), 200\n",
    "\n",
    "# Chatbot API endpoint\n",
    "@app.route(\"/\", methods=[\"POST\", \"OPTIONS\"])\n",
    "@cross_origin(origin='*')\n",
    "def chatbot():\n",
    "    global chain\n",
    "    global document_search\n",
    "    \n",
    "    # Check if the chain is initialized\n",
    "    if chain is None:\n",
    "        return jsonify({\"error\": \"Chain not initialized\"}), 500\n",
    "\n",
    "    # Get input data from the request\n",
    "    data = request.get_json()\n",
    "    \n",
    "    # Perform similarity search using document_search\n",
    "    docs = document_search.similarity_search(data[\"text\"])\n",
    "    \n",
    "    # Generate a response using the chain based on input documents and user's question\n",
    "    response = chain.run(input_documents=docs, question=data[\"text\"])\n",
    "    \n",
    "    # Respond with a JSON indicating the response message\n",
    "    return jsonify({\"message\": response}), 200\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
